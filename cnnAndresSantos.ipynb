{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conteo de imagenes en la carpeta espectrogramas\n",
    "imgpath = 'E:/TrabajoFinGrado/Data2Reducido'\n",
    "\n",
    "images = []#Aqui añadimos imagenes\n",
    "directories = []#Directorios\n",
    "dircount = []#Cuenta de imagenes en directorios\n",
    "prevRoot=''\n",
    "cant=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):#Se recorre TODO de la carpeta espectrogramas\n",
    "    for filename in filenames:#Establecemos regla para los archivos\n",
    "        if re.search(\"\\.png\", filename):#El paquete \"re\" es utilizado para busqueda de strings, por ello ponemos regla: aquellos que sean .png\n",
    "            cant=cant+1#Con este contador, contamos imagenes de cada directorio\n",
    "            filepath = os.path.join(root, filename)#Unimos directorio actual con el filename\n",
    "            image = plt.imread(filepath)#Se lee la imagen del file para luego ser introducida en un array\n",
    "            images.append(image)#Añadimos image a el array\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")#Se imprime el numero de imagenes\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)#Se imprime ruta del directorio id0001, id0002...\n",
    "                prevRoot=root\n",
    "                directories.append(root)#lista de directorios encontrados\n",
    "                dircount.append(cant)#añadimos numero de imagenes encontradas en cada directorio al array dircount\n",
    "                cant=0#Se actualiza a 0 la cuenta de imagenes\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)#Se añaden las etiquetas de las imagenes\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    "\n",
    "#Guardando el array de imagenes como npy.file\n",
    "np.save('images.npy', images)\n",
    "\n",
    "#Representacion OneHot de las labels\n",
    "y_labels_one_hot = to_categorical(labels)\n",
    "\n",
    "#Guardando las etiquetasOneHot como npy.file\n",
    "np.save('y_labels_one_hot.npy', y_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Barajar y dividir el conjunto de datos en el train y el de validacion\n",
    "filenames_shuffled, y_labels_one_hot_shuffled = shuffle(images, y_labels_one_hot)\n",
    "\n",
    "#Guardamos los conjuntos barajados\n",
    "#Despues se puede cargar con np.load()\n",
    "np.save('y_labels_one_hot_shuffled.npy', y_labels_one_hot_shuffled)\n",
    "np.save('filenames_shuffled.npy', filenames_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos conjunto de imagenes en array de tipo numpy\n",
    "filenames_shuffled_numpy = np.array(filenames_shuffled)\n",
    "\n",
    "#Separamos en train y validacion\n",
    "X_train_filenames, X_val_filenames, y_train, y_val = train_test_split(#X=imagenes; y=labels\n",
    "    filenames_shuffled_numpy, y_labels_one_hot_shuffled, test_size=0.2, random_state=1)\n",
    "\n",
    "print(X_train_filenames.shape) # (3800,)\n",
    "print(y_train.shape)           # (3800, 12)\n",
    "\n",
    "print(X_val_filenames.shape)   # (950,)\n",
    "print(y_val.shape)             # (950, 12)\n",
    "\n",
    "# Guardamos estos files de train y validacion de nuevo como .npy\n",
    "np.save('X_train_filenames.npy', X_train_filenames)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "np.save('X_val_filenames.npy', X_val_filenames)\n",
    "np.save('y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un CustomGeneratos que cargará nuestro dataset en lotes\n",
    "class My_Custom_Generator(keras.utils.Sequence):\n",
    "  \n",
    "  def __init__(self, image_filenames, labels, batch_size):\n",
    "    self.image_filenames = image_filenames\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self):\n",
    "    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.image_filenames[idx * self.batch_size: (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    \n",
    "    return np.array([\n",
    "            resize(imread('/content/all_images/' + str(file_name)), (80, 80, 3))\n",
    "               for file_name in batch_x])/255.0, np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos instancias de BatchGenerator\n",
    "batch_size = 32\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(X_train_filenames, y_train, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_val_filenames, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5), activation ='relu',input_shape=(80,80,3)))\n",
    "model.add(BatchNormalization(axis=3))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(axis=3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (5,5), activation ='relu'))\n",
    "model.add(BatchNormalization(axis=3))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (5,5), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(axis=3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (5,5), activation ='relu'))\n",
    "model.add(BatchNormalization(axis=3))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (5,5), activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(axis=3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation = \"relu\")) #Fully connected layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(60, activation = \"relu\")) #Fully connected layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(12, activation = \"softmax\")) #Classification layer or output layer\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=my_training_batch_generator,\n",
    "                   steps_per_epoch = int(3800 // batch_size),\n",
    "                   epochs = 10,\n",
    "                   verbose = 1,\n",
    "                   validation_data = my_validation_batch_generator,\n",
    "                   validation_steps = int(950 // batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
