{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "xz6SDJXZ6qS8",
    "outputId": "ba59d03f-c8d2-4307-ec1e-577f00fd758b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "HdZ-zDET6x4d",
    "outputId": "4455ca18-88e4-485a-8ca9-f43f894d086f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f1d95eed9e02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import utils\n",
    "#from keras import backend as Ke\n",
    "#from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xv-B__T67I2"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "#drive_path = '/content/drive'\n",
    "#project_path = drive_path + '/My Drive/BiometriaPorVoz'#Raiz\n",
    "#espectro_path = project_path + '/dataCNN/espectogramas'#Espectrogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "zampcQol7NEN",
    "outputId": "39d56f65-c062-432e-d830-e2c85d3d9713"
   },
   "outputs": [],
   "source": [
    "#Conteo de imagenes en la carpeta espectrogramas\n",
    "#dirname = os.path.join(os.getcwd(), espectro_path)#Unimos directorio actual con ruta de espectrogramas\n",
    "#imgpath = dirname + os.sep #contiene la ruta de espectrogramas con \"/\"\"\n",
    "imgpath = 'E:/TrabajoFinGrado/Data2'\n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):#Se recorre TODO de la carpeta espectrogramas\n",
    "    for filename in filenames:#Establecemos regla para los archivos\n",
    "        if re.search(\"\\.png\", filename):#El paquete \"re\" es utilizado para busqueda de strings, por ello ponemos regla: aquellos que sean .png\n",
    "            cant=cant+1#Con este contador, contamos imagenes de cada directorio\n",
    "            filepath = os.path.join(root, filename)#Unimos directorio actual con el filename\n",
    "            image = plt.imread(filepath)#Se lee la imagen del file para luego ser introducida en un array\n",
    "            images.append(image)#Añadimos image a el array\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")#Se imprime el numero de imagenes\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)#Se imprime ruta del directorio id0001, id0002...\n",
    "                prevRoot=root\n",
    "                directories.append(root)#lista de directorios encontrados\n",
    "                dircount.append(cant)#añadimos numero de imagenes encontradas en cada directorio al array dircount\n",
    "                cant=0#Se actualiza a 0 la cuenta de imagenes\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "PPoQ50sj-5eQ",
    "outputId": "d7583fc1-a7cb-4a60-c9d6-ea1bc77066b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1941\n",
      "0 id10001\n",
      "1 id10002\n",
      "2 id10003\n",
      "3 id10004\n",
      "4 id10005\n",
      "5 id10006\n",
      "6 id10007\n",
      "7 id10008\n",
      "8 id10009\n",
      "9 id10010\n",
      "10 id10011\n",
      "11 id10012\n",
      "12 id10013\n",
      "13 id10014\n",
      "14 id10015\n",
      "15 id10016\n",
      "16 id10017\n",
      "17 id10018\n",
      "18 id10019\n",
      "19 id10020\n",
      "Total number of outputs :  20\n",
      "Output classes :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)#Se añaden las etiquetas de las imagenes\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    "\n",
    "deportes=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)#obtienes solo el nombre del directorio\n",
    "    print(indice , name[len(name)-1])#me imprimes el indice y su directorio correspondiente\n",
    "    deportes.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    "\n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.float64) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zu1pgHRU-8lC"
   },
   "outputs": [],
   "source": [
    "#Parametros\n",
    "\n",
    "#numero de iteraciones sobre el set de datos\n",
    "epocas = 100\n",
    "\n",
    "#array donde mete cada uno de los pixeles\n",
    "altura = 100\n",
    "longitud = 100\n",
    "\n",
    "#numero de imagenes que procesa\n",
    "batch_size = 64\n",
    "\n",
    "#numero de veces que se procesa la informacion\n",
    "# 1 -> epoca tiene 1000 pasos\n",
    "pasos = 1000\n",
    "\n",
    "#al final de cada epoca para comprobar que aprende\n",
    "pasos_validacion = 200\n",
    "\n",
    "#primera convolucion\n",
    "filtros_convolucion1 = 32\n",
    "\n",
    "#segunda convolucion\n",
    "filtros_convolucion2 = 64\n",
    "\n",
    "#primera convolucion (altura,longitud)save_weights\n",
    "tamanyo_filtro1 = (3,3)\n",
    "\n",
    "#segunda convolucion (altura, longitud)\n",
    "tamanyo_filtro2 = (2,2)\n",
    "\n",
    "#tamaño filtro\n",
    "tamanyo_pool = (3,3)\n",
    "\n",
    "#clases = id (numero de carpetas)\n",
    "num_classes = 20\n",
    "\n",
    "#lr -> learning ratio\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "YW_l1WPk-6iA",
    "outputId": "b786accd-40e7-4bb7-b35a-d0b6c3a00d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1552, 100, 100, 4) (1552,)\n",
      "Testing data shape :  (389, 100, 100, 4) (389,)\n",
      "Original label: 14\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "(1241, 100, 100, 4) (311, 100, 100, 4) (1241, 20) (311, 20)\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)#Cargamos imagenes y etiquetas\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    "\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot =utils.to_categorical(train_Y)\n",
    "test_Y_one_hot = utils.to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    "\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    "\n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "Hz4NrVmeWNcN",
    "outputId": "7ba297e5-f4ca-48e9-842e-9614736695be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUpRfvc8/vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "_Aj_-Tzv_zRa",
    "outputId": "1635c7f8-f9da-470e-a8de-6a8910b2b358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 98, 98, 32)        1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 50)        25650     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               500100    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 611,066\n",
      "Trainable params: 611,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Creamos nuestra Red Neuronal CNN\n",
    "cnn = Sequential()\n",
    "\n",
    "#padding = 'same' -> que hace el filtro en las esquinas\n",
    "#input_shape -> las imagenes que entregamos a la primera capa tiene altura y longitud. El 3 se anyade por el RGB\n",
    "cnn.add(Convolution2D(filtros_convolucion1, tamanyo_filtro1,  input_shape=(altura, longitud, 4), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(Convolution2D(filtros_convolucion2, tamanyo_filtro2,  activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Añadido la ultima capa de 2D\n",
    "cnn.add(Convolution2D(128, tamanyo_filtro1, activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn.add(Convolution2D(50, tamanyo_filtro2,  activation='relu'))\n",
    "#Hace la imagen plana\n",
    "cnn.add(Flatten())\n",
    "\n",
    "#256 neuronas\n",
    "cnn.add(Dense(100, activation='relu'))\n",
    "#Durante el entrenamiento apaga el 50% de las neuronas -> esto se hace para evitar la sobreajustacion (Aleatorio)\n",
    "cnn.add(Dropout(0.25))\n",
    "#Ultima capa, nos ayuda a predecir que porcentaje de acierto tiene\n",
    "cnn.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Durante el entrenamiento su funcion de perdida si va bien o va mal\n",
    "#Optimizar con el learning ratio\n",
    "#Metrica -> si va bien\n",
    "cnn.compile(optimizer=optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "JF9aHHQiABpO",
    "outputId": "8369747c-c4d9-44e0-93d9-767808cbba35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1241 samples, validate on 311 samples\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 19s 15ms/sample - loss: 2.8971 - acc: 0.1918 - val_loss: 2.8174 - val_acc: 0.1897\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 18s 15ms/sample - loss: 2.8170 - acc: 0.2023 - val_loss: 2.8093 - val_acc: 0.1897\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 19s 15ms/sample - loss: 2.7925 - acc: 0.2039 - val_loss: 2.8053 - val_acc: 0.1897\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 19s 15ms/sample - loss: 2.7914 - acc: 0.2039 - val_loss: 2.8059 - val_acc: 0.1897\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - 18s 15ms/sample - loss: 2.7859 - acc: 0.2023 - val_loss: 2.8084 - val_acc: 0.1897\n",
      "Epoch 6/100\n",
      "1216/1241 [============================>.] - ETA: 0s - loss: 2.7870 - acc: 0.2015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2008059b6c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn.fit(train_X, train_label, batch_size=batch_size,epochs=epocas,verbose=1,validation_data=(test_X, test_Y_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hM_r_jQmCKWp"
   },
   "outputs": [],
   "source": [
    "modelos_dir = project_path + '/dataCNN/modelos'\n",
    "if not os.path.exists(modelos_dir):\n",
    "  os.mkdir(modelos_dir)\n",
    "cnn.save(modelos_dir + '/modelo.h5')\n",
    "cnn.save_weights(modelos_dir+'/pesos.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
